import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans

# loading the data from csv file to a Pandas DataFrame
customer_data = pd.read_csv('/kaggle/input/customer-segmentation-tutorial-in-python/Mall_Customers.csv')

  # first 5 rows in the dataframe
customer_data.head()

  # finding the number of rows and columns
customer_data.shape

  # getting some informations about the dataset
customer_data.info()

  # checking for missing values
customer_data.isnull().sum()

  X = customer_data.iloc[:,[3,4]].values

  print(X)

  # finding wcss value for different number of clusters

wcss = []

for i in range(1,11):
  kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
  kmeans.fit(X)

  wcss.append(kmeans.inertia_)

    # plot an elbow graph

sns.set()
plt.plot(range(1,11), wcss)
plt.title('The Elbow Point Graph')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()

kmeans = KMeans(n_clusters=5, init='k-means++', random_state=0)

# return a label for each data point based on their cluster
Y = kmeans.fit_predict(X)

print(Y)

# plotting all the clusters and their Centroids

plt.figure(figsize=(8,8))
plt.scatter(X[Y==0,0], X[Y==0,1], s=50, c='green', label='Cluster 1')
plt.scatter(X[Y==1,0], X[Y==1,1], s=50, c='red', label='Cluster 2')
plt.scatter(X[Y==2,0], X[Y==2,1], s=50, c='yellow', label='Cluster 3')
plt.scatter(X[Y==3,0], X[Y==3,1], s=50, c='violet', label='Cluster 4')
plt.scatter(X[Y==4,0], X[Y==4,1], s=50, c='blue', label='Cluster 5')

# plot the centroids
plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s=100, c='cyan', label='Centroids')

plt.title('Customer Groups')
plt.xlabel('Annual Income')
plt.ylabel('Spending Score')
plt.show()

import warnings
warnings.filterwarnings('ignore')

from sklearn.cluster import KMeans

# Assuming you've already trained the K-Means model and saved it as 'kmeans_model'

# Example input data for prediction
# The input data should match the order and types of features used in your model
# (Annual Income, Spending Score)
input_data = (60, 50)  # Example: Annual Income = 60k$, Spending Score = 50

# Convert the input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# Reshape the data as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)
# Make prediction using the trained K-Means model
# Load or reuse the previously trained KMeans model
kmeans_model = KMeans(n_clusters=5, init='k-means++', random_state=0)  # Example model initialization
kmeans_model.fit(X)  # Assuming 'X' is the data used for training

# Predict the cluster for the new input data
cluster_prediction = kmeans_model.predict(input_data_reshaped)[0]

# Assign names to clusters based on their characteristics
cluster_names = {
    0: "Low Income, Low Spending",
    1: "Low Income, High Spending",
    2: "Average Income, Average Spending",
    3: "High Income, Low Spending",
    4: "High Income, High Spending"
}

# Get the name of the predicted cluster
predicted_cluster_name = cluster_names.get(cluster_prediction, "Unknown Cluster")

print(f'The customer belongs to: {predicted_cluster_name}')

import pickle
from sklearn.cluster import KMeans

# Assuming you've already trained your K-Means model
kmeans_model = KMeans(n_clusters=5, init='k-means++', random_state=0)
kmeans_model.fit(X)  # Assuming 'X' is the data used for training

# Saving the trained K-Means model to a file
model_filename = 'customer_segmentation_kmeans_model.pkl'
with open(model_filename, 'wb') as file:
    pickle.dump(kmeans_model, file)

print(f"Model saved to {model_filename}")
                                  
          
